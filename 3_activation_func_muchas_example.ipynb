{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a hacer lo mismo que antes solo que ahora lo aplicamos a varias instancias \n",
    "# de un solo viaje.\n",
    "\n",
    "# Para esto vamos a definir una funcion que hace todo de una sola vez, es decir, \n",
    "# calcula los valores de cada neurona y finalmente el output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "robust-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definamos nuestra funcion RELU\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "def relu(input):\n",
    "    output = max(0, input)\n",
    "    # salida\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bizarre-knock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([3, 5]), array([ 1, -1]), array([0, 0]), array([8, 4])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definamos nuestros datos de entrada (las instancias)\n",
    "\n",
    "input_data = [np.array([3, 5]), np.array([ 1, -1]), np.array([0, 0]), np.array([8, 4])]\n",
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "figured-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora definimos la funcion !!\n",
    "# entradas  input_data_row y weights\n",
    "\n",
    "# Define predict_with_network()\n",
    "def predict_with_network(input_data_row, weights):\n",
    "\n",
    "    # Calculate node 0 value\n",
    "    node_0_input = (input_data_row * weights['node_0']).sum()\n",
    "    node_0_output = relu(node_0_input)\n",
    "\n",
    "    # Calculate node 1 value\n",
    "    node_1_input = (input_data_row * weights['node_1']).sum()\n",
    "    node_1_output = relu(node_1_input)\n",
    "\n",
    "    # Put node values into array: hidden_layer_outputs\n",
    "    hidden_layer_outputs = np.array([node_0_output, node_1_output])\n",
    "    \n",
    "    # Calculate model output\n",
    "    input_to_final_layer = np.array([node_0_output, node_1_output])\n",
    "    model_output = (hidden_layer_outputs * weights['output']).sum()\n",
    "    \n",
    "    # Return model output\n",
    "    return(model_output)\n",
    "\n",
    "\n",
    "# un diccionario que compone los pesos de la red\n",
    "weights = {'node_0': np.array([2, 4]), 'node_1': np.array([ 4, -5]), 'output': np.array([2, 7])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "typical-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora apliquemos nuestra funcion para cada uno de las instancias que estan en input_data\n",
    "\n",
    "# aqui vamos a ir guardando los resultados.\n",
    "results = []\n",
    "\n",
    "\n",
    "for input_data_row in input_data:\n",
    "    # Append prediction to results\n",
    "    results.append(predict_with_network(input_data_row, weights))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "finnish-musician",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52, 63, 0, 148]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becoming-pollution",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
