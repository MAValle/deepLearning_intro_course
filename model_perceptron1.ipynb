{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos JupyterLab para simular un perceptron.\n",
    "# El perceptron tendrá 8 entradas de atributos y una salida.\n",
    "# Vamos a \"entrenar\" los pesos del perceptron para un dataset con 8 aptributos y una clase.\n",
    "\n",
    "\n",
    "\n",
    "# Instalacion de paquetes y dependencias (esto debe ejecutarse en el terminal)\n",
    "# pip install keras\n",
    "# pip install tensorflow\n",
    "# pip install numpy\n",
    "# pip install scipy\n",
    "\n",
    "# De todas formas, si esta con ANACONDA, sugiero instalar tensorflow desde la aplicación anaconda. \n",
    "# Si numpy y scipy no están instaladas, hacerlo via anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de paquetes y dependencias\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carga de los datos\n",
    "# https://www.kaggle.com/uciml/pima-indians-diabetes-database\n",
    "\n",
    "# Context:\n",
    "# This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. \n",
    "# The objective of the dataset is to diagnostically predict whether or not a patient has diabetes, based on certain \n",
    "# diagnostic measurements included in the dataset. Several constraints were placed on the selection of these \n",
    "# instances from a larger database. In particular, all patients here are females at least 21 years old of Pima \n",
    "# Indian heritage.\n",
    "\n",
    "# Content:\n",
    "# The datasets consists of several medical predictor variables and one target variable, Outcome. Predictor \n",
    "# variables includes the number of pregnancies the patient has had, their BMI, insulin level, age, and so on.\n",
    "\n",
    "# Acknowledgements\n",
    "# Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning \n",
    "# algorithm to forecast the onset of diabetes mellitus. In Proceedings of the Symposium on Computer Applications \n",
    "# and Medical Care (pp. 261--265). IEEE Computer Society Press.\n",
    "\n",
    "# Clase:\n",
    "# Y = {0,1} =  {sin diabetes, diabetes}\n",
    "\n",
    "#dataset = np.loadtxt('pima_dataset.csv', delimiter=',')\n",
    "dataset = np.genfromtxt(\"pima_dataset.csv\", delimiter=\",\", skip_header=1) # sin cargar header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionamos los atributos de entrada X  y la clase Y\n",
    "\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
       "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
       "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
       "       ...,\n",
       "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
       "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
       "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora creamos el modelo y agregamos el perceptron, es cual es una Dense layer\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(Dense())\n",
    "#from tensorflow.keras.activations import hard_sigmoid\n",
    "\n",
    "# Al inicializar model.add(Dense()) tendremos un problema!\n",
    "# KERAS no esta diseñado para crear perceptrones. KERAS nos obliga a definir una función de activación \n",
    "# que sea \"continua\" y ademas una \"inicializacion\" o metodo de optimizacion (lo veremos mas adelante)\n",
    "\n",
    "# Explicación más detallada\n",
    "# Para el perceptron, nosotros usamos la funcion sgn, que no es continua! (no es diferenciable), condición\n",
    "# que es necesaria para la optimizacion (por ejemplo, el gradient descent)\n",
    "# Recordemos que los pesos en un perceptron se ajustan \"empujándolos\" en la dirección correcta (Learning rule).\n",
    "# Pero en KERAS en en redes neuronales, esto se hace a través de una función de perdida que es diferenciable\n",
    "# (lo veremso mas adelante). Al minimizar este gradiente, el algoritmo encuentra la manera de ajustar \n",
    "# los pesos. Esto se denomina Stochastic gradient descent. O sea, en vez de empujar los pesos en la dirección\n",
    "# correcta, es como descender montañas por la pendiente más pronunciada.\n",
    "\n",
    "# Como no podemos usar la función sgn, utilizamos una versión continua, muy similar y que es diferenciable y se \n",
    "# llama sigmoide:\n",
    "\n",
    "# sig(t) = 1/(1+e^(-t))\n",
    "\n",
    "# por lo tanto, incializamos así:\n",
    "model.add(Dense(units = 1, activation='hard_sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pero también decimos que el perceptron tendra 8 entradas (8 pesos)\n",
    "#model.add(Dense(1, input_shape=(8,), activation=hard_sigmoid, kernel_initializer='glorot_uniform'))\n",
    "model.add(Dense(1, input_shape=(8,), activation='hard_sigmoid', kernel_initializer='random_uniform'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora compilamos el modelo y lo inicializamos\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Nota:\n",
    "# La funcion de perdida que se utiliza para poder ir ajustando los pesos es la binary cross entropy que es \n",
    "# que se utilzia por defecto en la matyoría de las aplicaciones de clasificación \n",
    "# (Chollet, F. (2017). Deep Learning with Python. New York, NY: Manning Publications.)\n",
    "# El optimizador Adam es una estensión del gradient descent para ir ajustando los pesos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 614 samples, validate on 154 samples\n",
      "Epoch 1/225\n",
      "614/614 [==============================] - 1s 2ms/sample - loss: 0.6918 - accuracy: 0.6531 - val_loss: 0.6906 - val_accuracy: 0.6429\n",
      "Epoch 2/225\n",
      "614/614 [==============================] - 0s 147us/sample - loss: 0.6892 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.6429\n",
      "Epoch 3/225\n",
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6868 - accuracy: 0.6531 - val_loss: 0.6860 - val_accuracy: 0.6429\n",
      "Epoch 4/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6845 - accuracy: 0.6531 - val_loss: 0.6842 - val_accuracy: 0.6429\n",
      "Epoch 5/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6824 - accuracy: 0.6531 - val_loss: 0.6822 - val_accuracy: 0.6429\n",
      "Epoch 6/225\n",
      "614/614 [==============================] - 0s 161us/sample - loss: 0.6804 - accuracy: 0.6531 - val_loss: 0.6803 - val_accuracy: 0.6429\n",
      "Epoch 7/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6784 - accuracy: 0.6531 - val_loss: 0.6786 - val_accuracy: 0.6429\n",
      "Epoch 8/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6766 - accuracy: 0.6531 - val_loss: 0.6768 - val_accuracy: 0.6429\n",
      "Epoch 9/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6748 - accuracy: 0.6531 - val_loss: 0.6753 - val_accuracy: 0.6429\n",
      "Epoch 10/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6732 - accuracy: 0.6531 - val_loss: 0.6737 - val_accuracy: 0.6429\n",
      "Epoch 11/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6715 - accuracy: 0.6531 - val_loss: 0.6725 - val_accuracy: 0.6429\n",
      "Epoch 12/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6700 - accuracy: 0.6531 - val_loss: 0.6711 - val_accuracy: 0.6429\n",
      "Epoch 13/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6685 - accuracy: 0.6531 - val_loss: 0.6698 - val_accuracy: 0.6429\n",
      "Epoch 14/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6671 - accuracy: 0.6531 - val_loss: 0.6685 - val_accuracy: 0.6429\n",
      "Epoch 15/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6658 - accuracy: 0.6531 - val_loss: 0.6673 - val_accuracy: 0.6429\n",
      "Epoch 16/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6645 - accuracy: 0.6531 - val_loss: 0.6663 - val_accuracy: 0.6429\n",
      "Epoch 17/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6632 - accuracy: 0.6531 - val_loss: 0.6652 - val_accuracy: 0.6429\n",
      "Epoch 18/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6622 - accuracy: 0.6531 - val_loss: 0.6641 - val_accuracy: 0.6429\n",
      "Epoch 19/225\n",
      "614/614 [==============================] - 0s 163us/sample - loss: 0.6610 - accuracy: 0.6531 - val_loss: 0.6633 - val_accuracy: 0.6429\n",
      "Epoch 20/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6601 - accuracy: 0.6531 - val_loss: 0.6624 - val_accuracy: 0.6429\n",
      "Epoch 21/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6591 - accuracy: 0.6531 - val_loss: 0.6617 - val_accuracy: 0.6429\n",
      "Epoch 22/225\n",
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6582 - accuracy: 0.6531 - val_loss: 0.6609 - val_accuracy: 0.6429\n",
      "Epoch 23/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6573 - accuracy: 0.6531 - val_loss: 0.6602 - val_accuracy: 0.6429\n",
      "Epoch 24/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6566 - accuracy: 0.6531 - val_loss: 0.6595 - val_accuracy: 0.6429\n",
      "Epoch 25/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6558 - accuracy: 0.6531 - val_loss: 0.6589 - val_accuracy: 0.6429\n",
      "Epoch 26/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6551 - accuracy: 0.6531 - val_loss: 0.6582 - val_accuracy: 0.6429\n",
      "Epoch 27/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6544 - accuracy: 0.6531 - val_loss: 0.6578 - val_accuracy: 0.6429\n",
      "Epoch 28/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6538 - accuracy: 0.6531 - val_loss: 0.6574 - val_accuracy: 0.6429\n",
      "Epoch 29/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6533 - accuracy: 0.6531 - val_loss: 0.6569 - val_accuracy: 0.6429\n",
      "Epoch 30/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6528 - accuracy: 0.6531 - val_loss: 0.6563 - val_accuracy: 0.6429\n",
      "Epoch 31/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6522 - accuracy: 0.6531 - val_loss: 0.6561 - val_accuracy: 0.6429\n",
      "Epoch 32/225\n",
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6517 - accuracy: 0.6531 - val_loss: 0.6557 - val_accuracy: 0.6429\n",
      "Epoch 33/225\n",
      "614/614 [==============================] - 0s 147us/sample - loss: 0.6513 - accuracy: 0.6531 - val_loss: 0.6553 - val_accuracy: 0.6429\n",
      "Epoch 34/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6509 - accuracy: 0.6531 - val_loss: 0.6550 - val_accuracy: 0.6429\n",
      "Epoch 35/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6504 - accuracy: 0.6531 - val_loss: 0.6547 - val_accuracy: 0.6429\n",
      "Epoch 36/225\n",
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6501 - accuracy: 0.6531 - val_loss: 0.6543 - val_accuracy: 0.6429\n",
      "Epoch 37/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6497 - accuracy: 0.6531 - val_loss: 0.6541 - val_accuracy: 0.6429\n",
      "Epoch 38/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6494 - accuracy: 0.6531 - val_loss: 0.6539 - val_accuracy: 0.6429\n",
      "Epoch 39/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6491 - accuracy: 0.6531 - val_loss: 0.6536 - val_accuracy: 0.6429\n",
      "Epoch 40/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6488 - accuracy: 0.6531 - val_loss: 0.6534 - val_accuracy: 0.6429\n",
      "Epoch 41/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6486 - accuracy: 0.6531 - val_loss: 0.6533 - val_accuracy: 0.6429\n",
      "Epoch 42/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6483 - accuracy: 0.6531 - val_loss: 0.6531 - val_accuracy: 0.6429\n",
      "Epoch 43/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6481 - accuracy: 0.6531 - val_loss: 0.6530 - val_accuracy: 0.6429\n",
      "Epoch 44/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6479 - accuracy: 0.6531 - val_loss: 0.6528 - val_accuracy: 0.6429\n",
      "Epoch 45/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6477 - accuracy: 0.6531 - val_loss: 0.6527 - val_accuracy: 0.6429\n",
      "Epoch 46/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6475 - accuracy: 0.6531 - val_loss: 0.6526 - val_accuracy: 0.6429\n",
      "Epoch 47/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6473 - accuracy: 0.6531 - val_loss: 0.6525 - val_accuracy: 0.6429\n",
      "Epoch 48/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6472 - accuracy: 0.6531 - val_loss: 0.6524 - val_accuracy: 0.6429\n",
      "Epoch 49/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6471 - accuracy: 0.6531 - val_loss: 0.6523 - val_accuracy: 0.6429\n",
      "Epoch 50/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6470 - accuracy: 0.6531 - val_loss: 0.6522 - val_accuracy: 0.6429\n",
      "Epoch 51/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6468 - accuracy: 0.6531 - val_loss: 0.6522 - val_accuracy: 0.6429\n",
      "Epoch 52/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6467 - accuracy: 0.6531 - val_loss: 0.6521 - val_accuracy: 0.6429\n",
      "Epoch 53/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6466 - accuracy: 0.6531 - val_loss: 0.6521 - val_accuracy: 0.6429\n",
      "Epoch 54/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6465 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 55/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6465 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 56/225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6463 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 57/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6463 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 58/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6462 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 59/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6462 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 60/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 61/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 62/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 63/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 64/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 65/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 66/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 67/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 68/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 69/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 70/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 71/225\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 72/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 73/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 74/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 75/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 76/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 77/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 78/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 79/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 80/225\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 81/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 82/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 83/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 84/225\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 85/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 86/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 87/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 88/225\n",
      "614/614 [==============================] - 0s 145us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 89/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 90/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6518 - val_accuracy: 0.6429\n",
      "Epoch 91/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 92/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 93/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 94/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 95/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 96/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 97/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 98/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 99/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 100/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 101/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 102/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 103/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 104/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 105/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 106/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 107/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 108/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 109/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 110/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 111/225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 112/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 113/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 114/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 115/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 116/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 117/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6519 - val_accuracy: 0.6429\n",
      "Epoch 118/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 119/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 120/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 121/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 122/225\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 123/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 124/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 125/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 126/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 127/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 128/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 129/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 130/225\n",
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 131/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 132/225\n",
      "614/614 [==============================] - 0s 143us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 133/225\n",
      "614/614 [==============================] - 0s 148us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 134/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 135/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 136/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 137/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 138/225\n",
      "614/614 [==============================] - 0s 175us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 139/225\n",
      "614/614 [==============================] - 0s 146us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 140/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 141/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 142/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 143/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 144/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 145/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 146/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 147/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 148/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 149/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 150/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 151/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 152/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 153/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 154/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 155/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 156/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 157/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 158/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 159/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 160/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 161/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 162/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 163/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 164/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 165/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 166/225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 167/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 168/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 169/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 170/225\n",
      "614/614 [==============================] - 0s 148us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 171/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 172/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 173/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 174/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 175/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 176/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 177/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 178/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 179/225\n",
      "614/614 [==============================] - 0s 141us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 180/225\n",
      "614/614 [==============================] - 0s 147us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 181/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 182/225\n",
      "614/614 [==============================] - 0s 153us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 183/225\n",
      "614/614 [==============================] - 0s 146us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 184/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 185/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 186/225\n",
      "614/614 [==============================] - 0s 132us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 187/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 188/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 189/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 190/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 191/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 192/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 193/225\n",
      "614/614 [==============================] - 0s 142us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 194/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 195/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 196/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 197/225\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 198/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 199/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 200/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 201/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 202/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 203/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 204/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 205/225\n",
      "614/614 [==============================] - 0s 135us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 206/225\n",
      "614/614 [==============================] - 0s 132us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 207/225\n",
      "614/614 [==============================] - 0s 140us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 208/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 209/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 210/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 211/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 212/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 213/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 214/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 215/225\n",
      "614/614 [==============================] - 0s 133us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 216/225\n",
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 217/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 218/225\n",
      "614/614 [==============================] - 0s 137us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 219/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 220/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 221/225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "614/614 [==============================] - 0s 134us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 222/225\n",
      "614/614 [==============================] - 0s 139us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 223/225\n",
      "614/614 [==============================] - 0s 138us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 224/225\n",
      "614/614 [==============================] - 0s 144us/sample - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n",
      "Epoch 225/225\n",
      "614/614 [==============================] - 0s 136us/sample - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6520 - val_accuracy: 0.6429\n"
     ]
    }
   ],
   "source": [
    "# hacemos fit de datos en este psudo perceptron (entrenamiento).\n",
    "# Presentamos los datos a nuestro pseudo perceptron. Esto le dice a Keras que comience el proceso de \n",
    "# entrenamiento.\n",
    "    \n",
    "history = model.fit(X, Y, epochs=225, batch_size=25, verbose=1, validation_split=0.2)\n",
    "\n",
    "# epochs = numero de iteraciones del proceso de aprendizaje optimizacion antes de parar el proceso de aprendizaje\n",
    "# batch_size = tamaño de las muestras durante cada iteracion\n",
    "# verbose = 1 lo dejamos en 1 para ver que va sucediendo\n",
    "# split = 0.3  tomamos un 20% de los datos como set de validacion para evitar el overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vemos que el accuracy logra superar ligeramente el 60%.\n",
    "\n",
    "# Nota: Accuracy es una medida de desempeño que mide la capacidad del clasificador (en este caso, del perceptron)\n",
    "# para clasificar correctamente si la instancia es diabética o no.\n",
    "\n",
    "# No es un problema de clasificacion facil. Pensemos que estamos tratando de clasificar con solo un\n",
    "# perceptron (lineal). A pesar de eso, los resultados son notables.\n",
    "\n",
    "# Hemos visto cómo usar Keras como crear un perceptron (o al menos simular uno). No podemos crear un perceptron\n",
    "# ideal con Keras porque utiliza una funcion de activacion no diferenciable. \n",
    "\n",
    "\n",
    "# Referencias adicionales\n",
    "# Ariosa, R. (2018, April 27). MrRobb/keras-zoo. Retrieved from https://github.com/MrRobb/keras-zoo/blob/master/P%20(Perceptron)/readme.md\n",
    "# Chollet, F. (2017). Deep Learning with Python. New York, NY: Manning Publications.\n",
    "# Rosenblatt, F. (1957). The Perceptron – a Perceiving and Recognizing Automaton. Retrieved from UMass website: https://blogs.umass.edu/brain-wars/files/2016/03/rosenblatt-1957.pdf\n",
    "# Zakaria, Y. (2016, November 23). Non-smooth and non-differentiable customized loss function tensorflow. Retrieved from https://stackoverflow.com/a/40758135"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamos cómo se desarrolla el accuracy en las iteraciones\n",
    "# https://stackoverflow.com/questions/61401114/neural-network-perceptron-visualizing-decision-boundary-as-a-hyperplane-wh\n",
    "\n",
    "import matplotlib.pyplot as plt #cargamos paquete para graficar\n",
    "\n",
    "epochs = range(len(history.epoch))  #creamos un vector rango de 0 a 255\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history.history['accuracy'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Veamos un plot de la funcion de perdida a traves de las iteraciones\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, history.history['loss'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿podemos ver los pesos sinápticos finales?\n",
    "\n",
    "#extract weights and bias from model\n",
    "weights = model.layers[0].get_weights()[0]\n",
    "biases = model.layers[0].get_weights()[1]\n",
    "\n",
    "#w1 = weights[0][0] #a\n",
    "#w2 = weights[1][0] #b\n",
    "#w3 = weights[2][0] #c\n",
    "#b = biases[0]      #d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.5204925 ]\n",
      " [-0.5555905 ]\n",
      " [-0.7249668 ]\n",
      " [ 0.04434514]\n",
      " [-0.01109201]\n",
      " [-0.44990337]\n",
      " [ 0.19209158]\n",
      " [-0.38743228]]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Que interesante!  \n",
    "# De que manera se podrian interpretar estos pesos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
